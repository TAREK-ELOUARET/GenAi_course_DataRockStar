{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc16fbd9",
   "metadata": {},
   "source": [
    "# Leçon 6 — Architectures complexes : ResNet, GAN, Inception\n",
    "\n",
    "## Objectifs\n",
    "- Comprendre ResNet (skip), GAN (jeu minmax), Inception (branches parallèles)\n",
    "- Savoir quand utiliser chaque famille\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70338859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Bloc résiduel (ResNet) pédagogique ---\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, stride=1):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_ch, out_ch, 3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1   = nn.BatchNorm2d(out_ch)\n",
    "        self.relu  = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(out_ch, out_ch, 3, stride=1, padding=1, bias=False)\n",
    "        self.bn2   = nn.BatchNorm2d(out_ch)\n",
    "        self.downsample = None\n",
    "        if stride != 1 or in_ch != out_ch:\n",
    "            self.downsample = nn.Sequential(\n",
    "                nn.Conv2d(in_ch, out_ch, 1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_ch)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        out = self.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "x = torch.randn(2, 64, 56, 56)\n",
    "block = BasicBlock(64, 64)\n",
    "y = block(x)\n",
    "print(y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ff5971",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- GAN jouet (MNIST-like, une itération pédagogique) ---\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "latent_dim = 64\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 256), nn.ReLU(True),\n",
    "            nn.Linear(256, 512), nn.ReLU(True),\n",
    "            nn.Linear(512, 28*28), nn.Tanh()\n",
    "        )\n",
    "    def forward(self, z):\n",
    "        return self.net(z).view(-1,1,28,28)\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(28*28, 512), nn.LeakyReLU(0.2, True),\n",
    "            nn.Linear(512, 256), nn.LeakyReLU(0.2, True),\n",
    "            nn.Linear(256, 1), nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "G, D = Generator(), Discriminator()\n",
    "opt_G = optim.Adam(G.parameters(), lr=2e-4, betas=(0.5,0.999))\n",
    "opt_D = optim.Adam(D.parameters(), lr=2e-4, betas=(0.5,0.999))\n",
    "bce = nn.BCELoss()\n",
    "real_data = torch.randn(64,1,28,28).clamp(-1,1)\n",
    "batch_size = real_data.size(0)\n",
    "opt_D.zero_grad()\n",
    "z = torch.randn(batch_size, latent_dim)\n",
    "fake = G(z).detach()\n",
    "pred_real = D(real_data)\n",
    "pred_fake = D(fake)\n",
    "loss_D = bce(pred_real, torch.ones_like(pred_real)) + bce(pred_fake, torch.zeros_like(pred_fake))\n",
    "loss_D.backward(); opt_D.step()\n",
    "opt_G.zero_grad()\n",
    "z = torch.randn(batch_size, latent_dim)\n",
    "fake = G(z)\n",
    "pred = D(fake)\n",
    "loss_G = bce(pred, torch.ones_like(pred))\n",
    "loss_G.backward(); opt_G.step()\n",
    "print(f'loss_D={loss_D.item():.3f} | loss_G={loss_G.item():.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcc4513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Inception block (Keras) simplifié ---\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def inception_block(x, filters_1x1=32, filters_3x3=32, filters_5x5=16, filters_pool=16):\n",
    "    b1 = layers.Conv2D(filters_1x1, 1, activation='relu', padding='same')(x)\n",
    "    b2 = layers.Conv2D(filters_3x3, 3, activation='relu', padding='same')(x)\n",
    "    b3 = layers.Conv2D(filters_5x5, 5, activation='relu', padding='same')(x)\n",
    "    b4 = layers.MaxPooling2D(pool_size=3, strides=1, padding='same')(x)\n",
    "    b4 = layers.Conv2D(filters_pool, 1, activation='relu', padding='same')(b4)\n",
    "    return layers.Concatenate()([b1,b2,b3,b4])\n",
    "\n",
    "inp = keras.Input(shape=(64,64,3))\n",
    "x = inception_block(inp)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "out = layers.Dense(10, activation='softmax')(x)\n",
    "model = keras.Model(inp, out)\n",
    "model.summary()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}