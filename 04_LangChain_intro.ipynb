{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aab67df7",
   "metadata": {},
   "source": [
    "# Leçon 4 — Introduction à LangChain et son écosystème\n",
    "\n",
    "## Objectifs\n",
    "- Composer des chaînes (PromptTemplate → LLM → Parser)\n",
    "- Utiliser la mémoire, les outils et le RAG\n",
    "- Comprendre l'observabilité (traces) et l'évaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a1d558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Chaîne LangChain simple (OpenAI comme exemple) ---\n",
    "import os\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY', 'sk-...')\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "\n",
    "template = PromptTemplate.from_template(\n",
    "    'Tu es un formateur. En 4 puces, explique {concept} à un public B1.'\n",
    ")\n",
    "llm = ChatOpenAI(model='gpt-4o-mini', temperature=0.3)\n",
    "parser = StrOutputParser()\n",
    "chain = template | llm | parser\n",
    "result = chain.invoke({'concept': \"le mécanisme d'attention des Transformers\"})\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1f9916",
   "metadata": {},
   "source": [
    "> Local-first : Utilisez `langchain_community.llms.HuggingFacePipeline` pour brancher un pipeline Transformers au lieu d'un service hébergé."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}